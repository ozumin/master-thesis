\documentclass[
  11pt, % 本文のサイズ
  twocolumn, % 二段組
  headings=small, % sectionなどを小さく
]{scrartcl}
\usepackage[
  left=1.5cm,
  right=1.5cm,
  top=1.5cm,
  bottom=1.5cm
]{geometry}
\usepackage[hiragino-pron]{luatexja-preset} % 日本語化
\usepackage[main=japanese,english]{babel} % キャプションなどを日本語化
\usepackage{setspace}\setstretch{0.9} % 字間を詰める
\usepackage{multirow} % 表を縦に結合
%%% テンプレートの設定の始まり
\pagestyle{empty} % 頁番号を削除
\setlength{\arrayrulewidth}{.8pt} % 罫線の太さ
\setlength{\tabcolsep}{3pt}
\setkomafont{title}{\normalfont\mcfamily} % タイトルを太字にしない
\title{ %%% 
  \vspace*{-30pt}
  \begin{minipage}[t]{1.0\linewidth}
    \begin{center}
      \LARGE
      修\ \ 士\ \ 論\ \ 文\ \ 概\ \ 要\ \ 書\\[3pt]
      \large
      Summary of Master's Thesis
    \end{center}
    \begin{flushright}
      \normalsize      
      Date of submission: \提出日
    \end{flushright}
  \end{minipage}
  \vspace*{-20pt} % タイトル下の空間
}
\author{
  \begin{minipage}[t]{1.0\linewidth}
    \begin{center} % 表の大きさは調整した方が良いかも
      \normalsize
      % \fontsize{10pt}{12pt}\selectfont % もう少し小さくする場合
      \begin{tabular}{|c|p{3cm}|c|p{3cm}|c|p{3cm}|}
        \hline
        \shortstack{\\専攻名 (専門分野)\\Department}&電気・情報生命&
          \shortstack{\\氏名\\Name}&\氏名& 
          \multirow[c]{2}{4em}{\shortstack{\\指導教員\\Advisor}}&
          \multirow[c]{2}{5em}{村田 昇}
        \\ 
        \cline{1-4}
        \shortstack{\\研究指導名\\Research guidance}&情報学習システム& 
          \shortstack{\\学籍番号\\Student ID\\number}&\学籍番号&&
        \\ 
        \hline
        \shortstack{\\研究題目\\Title}&\multicolumn{5}{l|}{\研究題目}
        \\ 
        \hline
      \end{tabular}
    \end{center}
  \end{minipage}
}
\date{\vspace*{-30pt}}
%%% テンプレートの設定の始まり

%%% 以下必要に応じて変更
%% 必要なpackageの読み込みの例
\usepackage{graphicx}
\graphicspath{{./figures/}}
\usepackage{amsmath,amssymb}
\usepackage[fleqn,tbtags]{mathtools} % amsmathの拡張
\mathtoolsset{showonlyrefs,showmanualtags} 
%% 例の終わり
%% 
\def\氏名{永山 瑞生}
\def\学籍番号{5319E056-6}
\def\研究題目{NMFとバギングを用いたカルシウムイメージングデータのクラスタリング方法の一検討}
\def\提出日{02/29/2020}
\begin{document}
\maketitle
\thispagestyle{empty} % 表紙から頁番号を削除

%%% 以下本文の例
%%% (sectionだと大きいのでとりあえずsubsectionにしてみた)
\subsection*{研究背景}
脳内の情報伝達には複数のニューロンが関わっている．
そのため，同時活動するニューロングループの推定が脳の機能解明につながる可能性がある．
脳内の多くのニューロンを観察する方法に，蛍光イメージングの1つであるカルシウムイメージングがある．
ニューロンで活動電位が発生（発火）すると細胞内のCa${}^{2+}$濃度が上昇する．
カルシウムイメージングでは，このCa${}^{2+}$濃度上昇を蛍光で可視化する．
蛍光イメージングを用いる利点として，（1）高い空間分解能，（2）広い観察範囲，（3）遺伝子工学と併用して興奮性／抑制性ニューロンの同定などをした上での観察ができることが挙げられる．
一方，時間分解能が電気生理学的手法よりも低いことが蛍光イメージングの欠点である．
Ca${}^{2+}$濃度の変化はニューロンの電気的変化よりも遅く，また，カルシウム感受性蛍光分子のキネティクスも影響する．
さらに，カメラやレーザースキャンでのサンプリングレートは高くても100[Hz]程度であり，ニューロンの個々の発火を全て捉えるには不十分である．

本研究で扱うデータは，睡眠時と覚醒時のニューロンの活動を解析するために計測されたマウスのカルシウムイメージングデータである．
8[Hz]のサンプリングレートで1時間おきに15分間のイメージングが計6回行われ，100〜200個のニューロンが観測された．
8[Hz]のサンプリングレートではニューロンのシナプス伝達を抽出することはできないため，ニューロンの機能的なコネクティビティを抽出することを目標とする．
機能的なコネクティビティとは，つまり同時に活動するニューロンが持つ結合のことである．
よって本研究では，ニューロンのクラスタリングの問題を解く．
クラスタリングではグループに所属しないニューロンの推定とハードクラスタリングを目的とする．
提案アプローチによってどれほどの情報が抽出できるかを人工データ実験によって確かめる．
\subsection*{提案アプローチ}
ニューロンのクラスタリングには相互相関行列をクラスタリングする方法が考えられる．
しかし，相互相関行列ではグループに所属しないニューロンを閾値によって決めることは難しい．
提案アプローチではニューロン同士が同じグループになる確率値をバギングによって推定することで閾値を決めやすくする．
また，提案アプローチではnonnegative matrix factorization（NMF）を用いてニューロン間の隣接行列を推定する．
NMFの基底数の推定は難しいため，複数の基底数の推定結果を平均する．
NMFの推定量を隣接行列とするのは，異なる基底数で推定量のサイズが変化しないためである．

提案アプローチは2段階に分かれる．
まず，（1）ニューロン間の隣接行列$\bar{A}(X,\mathcal{K})$を推定し，（2）スペクトラルクラスタリングによってクラスタリングを行う．

% カルシウムイメージングデータに対していくつかの仮定をおいた．
% \\
% \noindent \textbf{仮定 1}\\
% グループが$K$個存在し，同じグループ内のニューロンは同時に活動する．
% ニューロンは複数のグループに所属することができる．
% 観測時間内ではグループに属するニューロンは変化しない．
% \\
% \textbf{仮定 2}\\
% 複数のグループが同時に活動する時，属するニューロンは被らない（ニューロンが属するグループは同時には活動しない）．
% \\
% これらの仮説をもとに，数理モデルを構築する．
ニューロン$i$の観測時系列は$x_{i:} \in \mathbb{R}_+^{J}$である．
$c_{k:} \in \mathbb{R}^J_+$ ($k=1,\dots,K$)をグループ$k$の活動の時系列とすると，仮定より$x_{i:}$は$c_{i:}$の重み付き和として表される：
\begin{equation}
	x_{i:} = \sum_{k=1}^K d_{ik} c_{k:} + \eta_{i:}.
  \label{eq:x}
\end{equation}
ただし，$d_{ik} \in \mathbb{R}^+$で，$\eta_{i:} \in \mathbb{R}^J$はガウスノイズの時系列である．
\eqref{eq:x}は行列形式で以下のように表現できる：
\begin{align}
  X &= DC + H.
  \label{eq:model_matrix}
\end{align}
ただし，$X \in \mathbb{R}_+^{I \times J}$，$D \in \mathbb{R}_+^{I \times K}$, $C \in \mathbb{R}_+^{K \times J}$, $H \in \mathbb{R}^{I \times J}$である．
また，$D$の要素$(i,k)$は$d_{ik}$，$C$の$i$行は$c_{i:}$，$H$の$i$行は$\eta_{i:}$である．

NMFは行列分解手法の一つであり，1つの非負行列を2つの非負行列の積として分解する．
提案アプローチでは，NMFを用いて\eqref{eq:model_matrix}を解いて$D$と$C$を求める．

NMFでの推定量を$\hat{A}(X, k)\in \{0,1\}^{I \times I}$とする．
NMFの寄与率行列$P \in \mathbb{R}^{I \times K}$の要素を次のように定義する：
\begin{align}
	p_{ik} &= \frac{||d_{ik} c_{k:}||_1}{\sum_{l=1}^K || d_{il} c_{l:} ||_1}
\end{align}
要素$p_{ik}$はニューロン$i$に対する基底$k$の寄与率という意味である．
$\hat{A}(X, k)$は，$P$の行ごとに最大値を1，それ以外を0とした行列$G$を用いて，
\begin{align}
	\hat{A}(X,k) = G G^{\top},
\end{align}
と定義する．
$\hat{A}(X,k)$は対称行列で，要素$\hat{a}_{ij}$はニューロン$i$とニューロン$j$が同じ基底に所属していると推定したら$1$，していないと推定したら$0$となる．

バギングを用いて隣接行列$\bar{A}(X, \mathcal{K}), \ \mathcal{K} = \{K_{min}, \dots, K_{max}\}$をブートストラップ推定量$\hat{A}$の平均として求める．
データ$X$からブートストラップサンプル$\{X^{*b}; b = 1,\dots, B\}$を作成し，$\hat{A}(X^{*b},k)$を推定する．
NMFでは基底数を決めなければならないが，確立された推定方法がなく難しい問題である．
基底数を間違えた時のリスクを下げるため，異なる基底数$\mathcal{K}$のモデル平均をとる．
$\bar{A}(X, \mathcal{K})$は$\hat{A}(X^{*b},k)$の期待値として算出する：
\begin{align}
	\bar{A}(X,\mathcal{K}) = \frac{1}{|\mathcal{K}|} \sum_{k \in \mathcal{K}} \frac{1}{B} \sum_{b=1}^B \hat{A}(X^{*b}, k).
\end{align}

$\bar{A}(X, \mathcal{K})$のクラスタリングにはスペクトラルクラスタリングを用いる．
スペクトラルクラスタリングは，隣接行列からグラフラプラシアンを求め，その固有ベクトルをk-meansなどでクラスタリングする手法である．
$\bar{A}(X, \mathcal{K})$は隣接行列なのでスペクトラルクラスタリングと相性が良いと考えられる．
\subsection*{実験結果}
ニューロン1000個の活動のシミュレーションを行い，人工のカルシウムイメージングデータを作成して，提案アプローチがどこまでうまく働くかを検証した．
その結果，NMFを使う有用性，バギングとモデル平均を用いることで精度の向上が確認できた．
\end{document}
